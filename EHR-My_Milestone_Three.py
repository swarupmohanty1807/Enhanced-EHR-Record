# -*- coding: utf-8 -*-
"""EHR-My Milestone Three.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yq0D_9pxa_xd6LvpIrB6G-Ody2hoL9ix

Milestone-3 is all about "Clinical Note Generation", "automate routine documentation" and "coding tasks using GenAI" .
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""Now i will upload the 3 different datasets i.e clinical data , patient records and lab reports for merging and further operations ."""

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

"""As i have uploaded the 3 datasets here , now i will write code to merge them and display the first few rows of the merged dataset."""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
try:
    lab_reports_df = pd.read_excel('lab_reports_datset.xlsx')
    clinical_data_df = pd.read_csv('clinical_data_heartfailure.csv')
    patient_records_df = pd.read_excel('patient records_heart attack_prediction dataset.xlsx')
    common_cols = ['Patient ID', 'icustay_id']
    # Merging the dataframes.
    merged_df = pd.merge(lab_reports_df, clinical_data_df, on=common_cols, how='outer')
    merged_df = pd.merge(merged_df, patient_records_df, on=common_cols, how='outer')
    # Displaying the first few rows of the merged dataframe.
    display(merged_df.head())
except FileNotFoundError as e:
    print(f"Error loading file: {e}. Please ensure the files were uploaded correctly.")
except KeyError as e:
    print(f"Error merging dataframes: {e}. Please ensure the common columns exist in all files.")
except Exception as e:
    print(f"An unexpected error occurred: {e}")

"""Now as i have merged the datasets successfully, in my next step, i will generate a new code cell that will take a patient ID as input and then display all the information available for that patient from the merged DataFrame ."""

patient_id_to_search = input("Enter the Patient ID you want to search for: ")
patient_details_df = merged_df[merged_df['Patient ID'] == patient_id_to_search]
# Checking if any details were found for the entered Patient ID.
if not patient_details_df.empty:
    print(f"Details for Patient ID: {patient_id_to_search}")
    display(patient_details_df)
else:
    print(f"No details found for Patient ID: {patient_id_to_search}")

"""Now i will access a pre-trained model from "Hugging Face" using the transformers library and the pipeline function."""

!pip install transformers
# Importing the pipeline function.
from transformers import pipeline
# Defining the task and the model name from Hugging Face.
task = "summarization"
model_name = "AbhinavSK/cikista-medical-report-summarizer" # Pre-trained Model name.
# Loading the pipeline.
try:
    nlp_pipeline = pipeline(task, model=model_name)
    print(f"Successfully loaded pipeline for task '{task}' using model '{model_name}'")
except Exception as e:
    print(f"Error loading pipeline: {e}")

"""Now i will summarize the patient details using the loaded model. For that i need to extract the relevant information from the "patient_details_df" DataFrame and format it as text that the summarization model can process.Then i can use the nlp_pipeline to generate the summary."""

patient_text = ""
for col in patient_details_df.columns:
    patient_text += f"{col}: {patient_details_df[col].iloc[0]}\n"
print("Patient Details Text for Summarization:")
print(patient_text)
# Using the loaded summarization pipeline to summarize the text.
try:
    summary = nlp_pipeline(patient_text, max_length=150, min_length=30, do_sample=False)
    print("\nSummary of Patient Details:")
    print(summary[0]['summary_text'])
except Exception as e:
    print(f"Error during summarization: {e}")

"""Now i will create a list to store the text representation of each patient's details."""

all_patients_text = []
# Iterating through each row of the merged_df DataFrame.
for index, row in merged_df.iterrows():
    patient_text = ""
    for col in merged_df.columns:
        patient_text += f"{col}: {row[col]}\n"
    all_patients_text.append(patient_text)
# printing the first few entries to see the format.
print("First 5 entries of the prepared dataset:")
for i in range(min(5, len(all_patients_text))):
    print(f"--- Patient {i+1} ---")
    print(all_patients_text[i])

""" Now i will access a preprocessed diagnosis model from "Hugging Face" ,and then in my next step i will use this model with our merged_df dataset."""

!pip install transformers
# Importing the pipeline function.
from transformers import pipeline
# Defining the task and the model name from Hugging Face.
task = "diagnosis"
model_name = "NeoAivara/Medical-Diagnosis-COT-DeepSeek" # Pre-processed model name.
# Loading the pipeline.
try:
    nlp_pipeline = pipeline(task, model=model_name)
    print(f"Successfully loaded pipeline for task '{task}' using model '{model_name}'")
except Exception as e:
    print(f"Error loading pipeline: {e}")

!pip install transformers
# Importing the pipeline function.
from transformers import pipeline
# Defining the model name.
model_name = "NeoAivara/Medical-Diagnosis-COT-DeepSeek"
# Attemptting to load the pipeline with a general text generation task.
try:
    nlp_pipeline_diagnosis = pipeline("text2text-generation", model=model_name)
    print(f"Successfully loaded pipeline for model '{model_name}' with 'text2text-generation' task.")
except Exception as e:
    print(f"Error loading pipeline with 'text2text-generation': {e}")
    try:
        nlp_pipeline_diagnosis = pipeline("text-generation", model=model_name)
        print(f"Successfully loaded pipeline for model '{model_name}' with 'text-generation' task.")
    except Exception as e_gen:
         print(f"Error loading pipeline with 'text-generation': {e_gen}")
         print("Could not load the model with a standard text generation task. Please check the model card on Hugging Face for correct usage.")